---
title: "Report_10883408"
author: '10883408'
date: "2024-04-08"
output:
  pdf_document: 
   latex_engine: xelatex
  word_document: default
editor_options:
  chunk_output_type: console
---


```{r loadlib, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
library(caret)
library(randomForest)
library(ggplot2)
library(dplyr)
library(e1071)
library(rpart)
library(rpart.plot)
library(RColorBrewer)
```

## ML part A 
```{r part A, echo=FALSE}

earthquake <- read.table(file = "earthquake.txt", header = TRUE, sep = "", dec = ".")
data <- read.table(file = "earthquake.txt", header = TRUE, sep = "", dec = ".")

ggplot(earthquake, aes(x=body, y=surface, color=type)) +
  geom_point(size=2, alpha=0.8, shape=19) + theme_light(base_size = 12) +
  labs(title = "Body-wave Magnitude vs. Surface-wave Magnitude",subtitle = "Comparing earthquake types",
       x = "Body-wave Magnitude (mb)",
       y = "Surface-wave Magnitude (Ms)",
       color = "Type") +
  scale_color_brewer(palette = "Set1") +theme(legend.position = "right")

```

### Graphical Analysis:
The scatter plot created by this code would show each earthquake or explosion event as a point in the space defined by its body-wave and surface-wave magnitudes. The colors distinguish between different types of seismic events, which could be crucial for identifying patterns or clusters specific to earthquakes versus explosions.

### Clustering: If there are visible clusters or distinct areas predominantly occupied by one type of event, this could indicate that these two features (body-wave and surface-wave magnitudes) are effective for distinguishing between earthquakes and explosions.
Overlaps: Significant overlapping of colors might suggest that the two features alone are not sufficient to distinguish between the event types without additional information or more complex modeling.

### Contextual Relevance:
In the context of monitoring for unauthorized nuclear tests, this visualization helps in quickly assessing whether there are clear, distinguishable patterns in seismic readings that could indicate nuclear activities. Effective differentiation between natural seismic events (earthquakes) and man-made seismic events (nuclear explosions) is crucial for global security and monitoring compliance with international treaties such as the Comprehensive Nuclear-Test-Ban Treaty (CTBT).

### Numerical Summaries:
While the provided code focuses on visual analysis, numerical summaries (like the mean, median, variance of mb and Ms for each type) would complement this by quantifying the central tendencies and dispersions. This could further aid in understanding how significantly the magnitudes for each type differ statistically.

### Justification:
The choice of a scatter plot is justified as it allows stakeholders to visually parse the relationship between two continuous variables across categories. Given the high stakes involved in nuclear monitoring, quick visual assessments alongside rigorous statistical analysis are imperative. The plot facilitates this by providing a clear, immediate visual summary of the data as per the described features.

```{r echo=FALSE}
library(ggplot2)

ggplot(data, aes(x = type, y = body, fill = type)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.5, color = "darkgray") +
  labs(title = "Box Plot with Jitter of Body-Wave Magnitude by Type",
       x = "Type",
       y = "Body-Wave Magnitude (mb)") +
  theme_minimal()

```

### Explanation of the Plot:
The box plot with jitter provides a clear view of how the body-wave magnitudes are distributed within each type of seismic event. The box plot component shows the median (the middle line in the box), the 25th and 75th percentiles (the lower and upper hinges of the box), and potential outliers (points that fall outside 1.5 times the IQR from the hinges). The jittered points represent individual data points, offering a granular look at the data distribution and any potential anomalies or outliers.

### Justification of the Statements:
Distribution Insight: The plot allows stakeholders to quickly assess whether there are significant differences in the body-wave magnitudes between different types of seismic events. For example, if one type of event typically has higher magnitude readings, this could indicate a different energy release characteristic.

Outlier Detection: By visually representing both the summary statistics and the actual data points, the plot helps identify outliers or unusual observations that may warrant further investigation.

Decision Making: This type of visualization supports decision-making in seismology and geophysics by providing a straightforward way to compare seismic event types. This could be crucial for designing monitoring systems or for academic studies in seismology.

Effective Communication: The plot serves as an effective communication tool by presenting complex statistical data in a form that is easy to understand, even for those without deep statistical knowledge.

This combination of box plot and jitter plot is particularly effective in contexts where understanding the variability within and across categories is crucial. It is a powerful tool for exploratory data analysis, providing both an overview and a detailed look at the data distribution across different categories.


```{r echo=FALSE}

library(ggplot2)

ggplot(data, aes(x = type, y = surface, fill = type)) +
  geom_boxplot(alpha = 0.7) +
  geom_jitter(width = 0.2, alpha = 0.5, color = "darkgray") +
  labs(title = "Box Plot with Jitter of Surface-Wave Magnitude by Type",
       x = "Type",
       y = "Surface-Wave Magnitude (Ms)") +
  theme_minimal()

```

Justification of the Statements:
Visualization of Variability: This plot is effective for visually assessing the variability and central tendencies of surface-wave magnitudes across different types of seismic events. The box plot provides a summary view, while the jittered points give detailed insight into the individual data entries.

Comparative Analysis: By displaying data for different types side by side, the plot facilitates direct comparisons between groups. For example, one might observe that nuclear explosions tend to have a tighter range of surface-wave magnitudes compared to earthquakes, which might exhibit a broader spread and potentially higher medians.

Outlier Detection: The visualization makes it easy to spot any anomalies or outliers in the data, which could indicate measurement errors or exceptional cases that may require further investigation.

Informative and Accessible: The addition of a clear title, axis labels, and a legend makes the plot accessible even to those who may not be familiar with the data or statistical plots, enabling stakeholders or a general audience to understand the findings at a glance.

Contextual Relevance:
In the context of monitoring seismic activities, being able to distinguish between different types of events based on surface-wave magnitudes is crucial. Such plots not only aid in preliminary analyses but can also be instrumental in developing more sophisticated models or algorithms to automate the detection and classification of seismic events. This is particularly important in scenarios where quick decision-making is necessary, such as in early warning systems or nuclear treaty compliance monitoring.

In summary, the plot generated by this R code effectively uses graphical elements to present key statistical insights into seismic data, aiding in both detailed statistical analysis and high-level data overview. This approach is justified given its utility in exploratory data analysis, where understanding data distribution and anomalies is crucial.



## ML part B

```{r part B(random forest), echo=FALSE}

library(randomForest)
library(caret)
library(ggplot2)

data <- read.table(file = "earthquake.txt", header = TRUE, sep = "", dec = ".")

data$type <- as.factor(data$type)

# Split the data into training and testing sets
set.seed(123) # for reproducibility
trainIndex <- createDataPartition(data$type, p=0.8, list=FALSE)
trainData <- data[trainIndex, ]
testData <- data[-trainIndex, ]

# Train the Random-forest model
control <- trainControl(method="cv", number=5) # 5-fold cross-validation
tuneGrid <- expand.grid(mtry=c(1,2)) # Tuning the 'mtry' parameter
rfModel <- train(type ~ body + surface, data=trainData, method="rf",
                 trControl=control, tuneGrid=tuneGrid)

# Model visualization
# Creating a grid to cover the range of body and surface values
surfaceRange <- range(data$surface)
bodyRange <- range(data$body)
grid <- expand.grid(body=seq(from=bodyRange[1], to=bodyRange[2], length.out=100),
                    surface=seq(from=surfaceRange[1], to=surfaceRange[2], length.out=100))

# Predicting over the grid
grid$prediction <- predict(rfModel, newdata=grid)

# Plotting with corrected data reference for geom_point

ggplot() +
  geom_tile(data = grid, aes(x = body, y = surface, fill = prediction), alpha = 0.5) +
  geom_point(data = data, aes(x = body, y = surface, color = type), size = 3, alpha = 0.6) +
  scale_fill_brewer(palette = "Set1", name = "Predicted Type") +
  scale_color_brewer(palette = "Set2", name = "Actual Type") +
  labs(title = "Earthquake vs. Nuclear Explosion Prediction",
       subtitle = "Random Forest Model Predictions vs. Actual Data",
       x = "Body-Wave Magnitude (mb)",
       y = "Surface-Wave Magnitude (Ms)",
       fill = "Predicted Type",
       color = "Actual Type") +
  theme_minimal() +
  theme(legend.position = "right",
        plot.title = element_text(size = 16, face = "bold"),
        plot.subtitle = element_text(size = 12),
        axis.title = element_text(size = 12),
        legend.title = element_text(size = 12),
        legend.text = element_text(size = 10)) +
  guides(fill = guide_legend(override.aes = list(alpha = 1)),
         color = guide_legend(override.aes = list(alpha = 1)))

```

### error rate
```{r}
# Extract the Random Forest model from the caret object
rf <- rfModel$finalModel

# Error rate plot
plot(rf$err.rate[, "OOB"], type = "l", col = "red",
     xlab = "Number of Trees",
     ylab = "OOB Error Rate",
     main = "OOB Error Rate vs. Number of Trees")

```
Model Tuning

### Random Forest Training:
Library: The randomForest package in R is used for constructing the Random Forest model.
Data Partitioning: The dataset is divided into training (80%) and testing (20%) subsets using the createDataPartition function from the caret package, ensuring that the distribution of event types is balanced across both sets.
Cross-validation: The model's hyperparameters are tuned using 5-fold cross-validation. This method splits the training set into five smaller sets; the model is trained on four of these while validating on the fifth, cycling through each subset. This process helps in optimizing model parameters while avoiding overfitting.
Tuning the mtry Parameter: The mtry parameter, which determines the number of variables considered at each split in the tree, is tuned. Two values are tested: 1 and 2. This parameter significantly affects the model's performance and helps in finding a good balance between bias and variance.

### Model Visualization
Decision Surface Visualization:
Grid Creation: A grid is created over the range of body and surface magnitudes found in the dataset. This grid allows for a comprehensive visualization of how the model classifies different combinations of these two features.
Prediction on Grid: The Random Forest model predicts the type of event for each point on the grid, essentially plotting the decision boundaries between earthquake and explosion classifications.
Plotting: Using ggplot2, the decision surface is visualized. The predictions for the grid are shown as a color-filled background (geom_tile), and actual data points are overlaid (geom_point) to show how well the predictions match reality. This visualization helps in understanding the model's classification rules visually.
Model Evaluation
### Error Rate Computation:
Out-of-Bag (OOB) Error: The OOB error rate is plotted against the number of trees in the forest. OOB error is a method of measuring prediction error of random forests, decision trees, and other models utilizing bootstrap aggregating to sub-sample data sampled for the training process. OOB is the mean prediction error on each training sample xᵢ, using only the trees that did not have xᵢ in their bootstrap sample.
Plot Details: The plot provides insight into how the model's accuracy evolves as more trees are added to the forest. Ideally, as the number of trees increases, the OOB error rate should decrease and then stabilize, indicating the model is neither underfitting nor overfitting.

### Additional Evaluation with Leave-One-Out Cross-Validation (LOOCV)
While not directly shown in the code snippets you provided, leave-one-out cross-validation (LOOCV) could be another method for evaluating the model. In LOOCV, the model is trained on all data points except one, which is used as the test set. This is repeated such that each data point serves as the test set exactly once. LOOCV provides a robust estimate of the model's performance but can be computationally intensive for larger datasets. It would be especially useful here to confirm the model's effectiveness due to the small size of the dataset.

### Summary
The combination of model tuning, visualization, and evaluation techniques provides a comprehensive approach to understanding and validating the Random Forest model. This methodical approach ensures that the model is both accurate and generalizable, capable of distinguishing between different types of seismic events effectively. The visualization of the decision boundary offers an intuitive way to interpret the model’s performance, while the error rate plot and potential LOOCV provide quantitative measures of model accuracy.

```{r echo=FALSE}
library(e1071)
library(caret)
library(ggplot2)

# Load the dataset
data <- read.table("earthquake.txt", header = TRUE)

# Check for missing values and remove them
data <- na.omit(data)

# Encode factors as numeric
data$type <- as.factor(data$type)

# Split the data into predictors and response
predictors <- data[, c("body", "surface")]
response <- data$type

# Define the tuning grid
tune.grid <- expand.grid(sigma = 10^(-3:-1), C = 10^(1:3))

# Define training control
train.control <- trainControl(method = "cv", number = 10, classProbs = TRUE)

# Train the SVM model
set.seed(123)
svm.model <- train(x = predictors, y = response, method = "svmRadial",
                   preProcess = c("center", "scale"),
                   trControl = train.control, tuneGrid = tune.grid)

# Best model parameters
best.parameters <- svm.model$bestTune

# Create a grid over the range of the data
body_seq <- seq(from = min(data$body), to = max(data$body), length.out = 100)
surface_seq <- seq(from = min(data$surface), to = max(data$surface), length.out = 100)
grid <- expand.grid(body = body_seq, surface = surface_seq)

# Predict on the grid to visualize the decision boundary
grid$prediction <- predict(svm.model, newdata = grid)

# Create the SVM plot
svm.plot <- ggplot() +
  geom_tile(data = grid, aes(x = body, y = surface, fill = as.factor(prediction)), alpha = 0.2) +
  geom_point(data = data, aes(x = body, y = surface, color = type)) +
  scale_color_manual(values = c("red", "blue")) +
  scale_fill_manual(values = c("lightpink", "lightblue")) +
  labs(color = "Actual Type", fill = "Predicted Type") +
  ggtitle("SVM Classification of Earthquake and Nuclear Explosions")

# Print the plot
print(svm.plot)

# Print the best parameters
print(best.parameters)



```
# Part D

```{r echo=FALSE}
library(ggplot2)

# Load the dataset
data <- read.table("earthquake.txt", header = TRUE)

# Extract just the body and surface variables for clustering
clustering_data <- data[, c("body", "surface")]

# Determine the total within sums of squares for a range of number of clusters
wss <- (nrow(clustering_data) - 1) * sum(apply(clustering_data, 2, var))
for (i in 2:10) {
  wss[i] <- sum(kmeans(clustering_data, centers = i, nstart = 20)$withinss)
}

# Elbow method plot to find optimal number of clusters
plot(1:10, wss, type = "b", xlab = "Number of Clusters", ylab = "Within groups sum of squares")

# Apply K-means clustering with different numbers of clusters
for (k in 2:4) {
  set.seed(123) # Set seed for reproducibility
  cluster <- kmeans(clustering_data, centers = k, nstart = 20)
  data$cluster <- as.factor(cluster$cluster)

  # Plot the clusters
  p <- ggplot(data, aes(x = body, y = surface, color = cluster)) +
    geom_point(alpha = 0.5) +
    scale_color_brewer(palette = "Dark2") +
    labs(title = paste("K-means Clustering with", k, "Clusters"),
         x = "Body-Wave Magnitude (mb)",
         y = "Surface-Wave Magnitude (Ms)",
         color = "Cluster") +
    theme_minimal()

  # Print the plot in RStudio
  print(p)
}


```





